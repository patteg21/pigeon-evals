task: sample
dataset_path: "data/docs"
generator: { provider: "openai", model: "gpt-4o-mini" }
# processors: ["tables", "breaks"] # toc
# embedding: 
#   provider: "openai"
#   model: "text-embedding-3-small"
#   pooling_strategy: "mean"  # mean, max, weighted, smooth_decay
#   # dimension_reduction: {type: "PCA", dims: 512} 
#   use_threading: true
#   max_workers: 8

# storage:
#   text_store: 
#     client: "sqlite"
#     upload: false

#   vector:
#     upload: false
#     clear: false
#     index: "sec-embeddings"
    
#   outputs: ["chunks", "documents"]


report:

  retrieval: 
    top_k: 100
    rerank:
      provider: "huggingface"
      model: "cross-encoder/ms-marco-MiniLM-L-6-v2" # TODO: Find a model
      top_k: 10
      
  metrics: ["precision", "recall", "hit-rate", "mrr", "ndcg"]  
  default_test: ""
  tests:
    - type: "agent"
      name: "AWS Earnings Test"
      prompt: "You are a helpful assistant Agent to discover more about the SEC Documnets in your tools"
      query: "Get me information on the latest earnings of AWS from 2024"
      mcp: 
        command: "uv"
        args:
          - "--directory"
          - "/Users/patteg/Desktop/development/gp-mcp-demo/"
          - "run"
          - "main.py"

    - type: "llm"
      name: "LLM Retrieval Judge"
      prompt: "You are a strict grader. Score 1-5 for relevance and faithfulness..."
      query: "Get me information on the latest revenue of AWS"


    - type: "human"
      name: "Sample Retrieval Results"
      query: "TSLA Earnings"


